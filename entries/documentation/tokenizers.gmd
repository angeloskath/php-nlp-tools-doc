---
[metadata]
title=Tokenizers
documentation=1
[options]
layout=layouts/page.php
---

Tokenizing in regards to computer science, to quote [wikipedia](http://en.wikipedia.org/wiki/Tokenizing),
is the process of converting a sequence of characters to a sequence of
tokens.

In NLP we tokenize a large piece of text to generate tokens which are
smaller pieces of text (words, sentences, etc.) that are easier to work
with. For instance we might want to apply a [stop word list ](http://en.wikipedia.org/wiki/Stop_words),
we will be applying it to the tokens and not the original text.

### Tokenizer interface ###

The tokenizer interface is a very simple one with only one method.

~~~ php
interface Tokenizer
{
	/*
	 * @param string $str The text for tokenization
	 * @return array The list of tokens from the string
	 */
	public function tokenize($str);
}
~~~

NlpTools does not introduce a new data structure for the token sequences
they are plain arrays.

### Tokenizers provided ###

The following tokenizers reside in the _\NlpTools\Tokenizers_ namespace.

1. WhitespaceTokenizer
2. WhitespaceAndPunctuationTokenizer
3. ClassifierBasedTokenizer

~~~ php
use \NlpTools\Tokenizers\WhitespaceTokenizer;
use \NlpTools\Tokenizers\WhitespaceAndPunctuationTokenizer;
use \NlpTools\Tokenizers\ClassifierBasedTokenizer;

$s = "Please allow me to introduce myself 
        I'm a man of wealth and taste";

$space = new WhitespaceTokenizer();
$punct = new WhitespaceAndPunctuationTokenizer();
// instantiate a binary classifier that chooses among the labels
// EOW --> End Of Word
// O   --> Other
// $cls <-- that classifier
$clstok = new ClassifierBasedTokenizer($cls);

$space->tokenize($s);
// array('Please','allow','me','to','introduce','myself',
//		'I\'m','a','man','of','wealth','and','taste')

$punct->tokenize($s);
// array('Please','allow','me','to','introduce','myself',
//		'I','\'','m','a','man','of','wealth','and','taste')

$clstok->tokenize($s);
// output depends on the classifier
~~~

### Classifier based tokenization ###

The constructor of the ClassifierBasedTokenizer looks like this

~~~ php
class ClassifierBasedTokenizer implements Tokenizer
{
	public function __construct(Classifier $cls, Tokenizer $tok=null,$sep=' ') {
		...
	}
	...
~~~

We will see how the classifier based tokenizer works with a simple
example that implements a naive rule based sentence tokenizer and then I
will explain a bit the simple algorithm that this tokenizer uses.

_ClassifierBasedTokenizer_ sends to the classifier a document of type
_WordDocument_ (you might want to check [the documents documentation](/documentation/documents.html)).

~~~ php
<?php

include ('vendor/autoload.php');

use \NlpTools\Tokenizers\ClassifierBasedTokenizer;
use \NlpTools\Tokenizers\WhitespaceTokenizer;
use \NlpTools\Classifiers\Classifier;
use \NlpTools\Documents\Document;

class EndOfSentence implements Classifier
{
	public function classify(array $classes, Document $d) {
		list($token,$before,$after) = $d->getDocumentData();
		
		$dotcnt = count(explode('.',$token))-1;
		$lastdot = substr($token,-1)=='.';
		
		if (!$lastdot) // assume that all sentences end in full stops
			return 'O';
		
		if ($dotcnt>1) // to catch some naive abbreviations U.S.A.
			return 'O';
		
		return 'EOW';
	}
}

$tok = new ClassifierBasedTokenizer(
	new EndOfSentence(),
	new WhitespaceTokenizer()
);

$text = "We are what we repeatedly do.
		Excellence, then, is not an act, but a habit.";

print_r($tok->tokenize($text));

// Array
// (
//    [0] => We are what we repeatedly do.
//    [1] => Excellence, then, is not an act, but a habit.
// )
~~~

ClassifierBasedTokenizer follows the following simple algorithm to
combine tokens from another tokenizer into larger tokens.

1. Break the character sequence into a token sequence using another
   Tokenizer instance
2. Classify each token whether it is an EOW or an O. EOW stands for
   "End of word" and O stands for "Other".
3. Join all O tokens up to an EOW token using a given separator (any
   character sequence)

<div style="text-align: center;" markdown="1">
[&laquo; Getting started](documentation/)
/
[Documents &raquo;](documentation/documents.html)
</div>
